---
title: "6: Data Exploration"
author: "Environmental Data Analytics | Kateri Salk"
date: "Spring 2019"
output: pdf_document
geometry: margin=2.54cm
fig_width: 5
fig_height: 2.5
editor_options: 
  chunk_output_type: console
---

## LESSON OBJECTIVES
1. Set up a data analysis session in RStudio
2. Import and explore datasets in R
3. Apply data exploration skills to a real-world example dataset

## OPENING DISCUSSION: WHY DO WE EXPLORE OUR DATA?

Why is data exploration our first step in analyzing a dataset? What information do we gain? How does data exploration aid in our decision-making for data analysis steps further down the pipeline?

## IMPORT DATA AND VIEW SUMMARIES

```{r}
# 1. Set up your working directory
getwd()

# 2. Load packges
library(tidyverse)

# 3. Import datasets
USGS.flow.data <- read.csv("./Data/Raw/USGS_Site02085000_Flow_Raw.csv")

View(USGS.flow.data)
# Alternate option: click on data frame in Environment tab

class(USGS.flow.data)
colnames(USGS.flow.data)

# Rename columns
colnames(USGS.flow.data) <- c("agency_cd", "site_no", "datetime", 
                              "discharge.max", "discharge.max.approval", 
                              "discharge.min", "discharge.min.approval", 
                              "discharge.mean", "discharge.mean.approval", 
                              "gage.height.max", "gage.height.max.approval", 
                              "gage.height.min", "gage.height.min.approval", 
                              "gage.height.mean", "gage.height.mean.approval")
str(USGS.flow.data)
dim(USGS.flow.data)

#head(USGS.flow.data)
class(USGS.flow.data$datetime)

```

## ADJUSTING DATASETS

### Formatting dates

R will often import dates as factors or characters rather than dates. To fix, this we need to tell R that it is looking at dates. We also need to specify the format the dates are in. By default, if you don't provide a format, R will attempt to use %Y-%m-%d or %Y/%m/%d as a default. Note: if you are working collaboratively in an international setting, using a year-month-day format in spreadsheets is the least ambiguous of date formats. Make sure to check whether month-day-year or day-month-year is used in an ambiguously formatted spreadsheet.

Formatting of dates in R: 

%d  day as number (0-31)
%m  month (00-12, can be e.g., 01 or 1)
%y  2-digit year
%Y  4-digit year
%a  abbreviated weekday
%A  unabbreviated weekday
%b  abbreviated month
%B  unabbreviated month

In some cases when dates are provided as integers, you may need to provide an origin for your dates. Beware: the "origin" date for Excel (Windows), Excel (Mac), R, and MATLAB all have different origin dates. Google this if it comes up.

```{r}
help(as.Date)

# Adjust date formatting for today
# Write code for three different date formats. 
# An example is provided to get you started.
# (code must be uncommented)
today <- Sys.Date()
format(today, format = "%B")
format(today, format = "%y")
format(today, format = "%a %D")
format(today, format = "%A, %b %dth, %Y")

USGS.flow.data$datetime <- as.Date(USGS.flow.data$datetime, format = "%m/%d/%y") 
```

Note that for every date prior to 1969, R has assigned the date in the 2000s rather than the 1900s. This can be fixed with an `ifelse` statement inside a function. Run through the code below and write what is happening in the comment above each line.

```{r}
# Changes the format of the date to two digit year two digit month day
USGS.flow.data$datetime <- format(USGS.flow.data$datetime, "%y%m%d")

#makes function so that all data points after date december 31 2018 (like the year 2024) are changed to 19 as first two numbers of year instead of 20. paste0 ammends the beginning of vectors
create.early.dates <- (function(d) {
       paste0(ifelse(d > 181231,"19","20"),d)
       })

#applies function to the datetime column of the dataframe
USGS.flow.data$datetime <- create.early.dates(USGS.flow.data$datetime)

#changes the format of the year in the data frame to be four digit year two digit month day
USGS.flow.data$datetime <- as.Date(USGS.flow.data$datetime, format = "%Y%m%d") 

```

### Removing NAs

Notice in our dataset that our discharge and gage height observations have many NAs, meaning no measurement was recorded for a specific day. In some cases, it might be in our best interest to remove NAs from a dataset. Removing NAs or not will depend on your research question.

```{r}
summary(USGS.flow.data$discharge.mean)
summary(USGS.flow.data$gage.height.mean)
```
Question: What types of research questions might make it favorable to remove NAs from a dataset, and what types of research questions might make it favorable to retain NAs in the dataset?

> Answer: 

```{r}
USGS.flow.data.complete <- na.omit(USGS.flow.data) #removes entire row that contains NA
dim(USGS.flow.data)
dim(USGS.flow.data.complete)

#complete.cases will tel you which cases are complete (up to 1000 rows)


mean(USGS.flow.data.complete$discharge.mean)
sd(USGS.flow.data.complete$discharge.mean)
summary(USGS.flow.data.complete$discharge.mean)

```

## VISUALIZATION FOR DATA EXPLORATION

Although the `summary()` function is helpful in getting an idea of the spread of values in a numeric dataset, it can be useful to create visual representations of the data to help form hypotheses and direct downstream data analysis. Below is a summary of the useful types of graphs that can be 

Note: each of these approaches utilize the package "ggplot2". We will be covering the syntax of ggplot in a later lesson, but for now you should familiarize yourself with the functionality of what each command is doing.

### Bar Chart (function: geom_bar)

Visualize count data for categorical variables. 

```{r, fig.height = 3, fig.width = 4}
ggplot(USGS.flow.data.complete, aes(x = discharge.mean.approval)) +
  geom_bar()
#geom_bar gives a bar graph 
#aes is aesthetics 
```

### Histogram (function: geom_histogram)

Visualize distributions of values for continuous numerical variables. What is happening in each line of code? Insert a comment above each line.

```{r, fig.height = 3, fig.width = 4}
#automatically makes 30 bins.  aes can be in ggplot or geom_histogram
ggplot(USGS.flow.data.complete) +
  geom_histogram(aes(x = discharge.mean))

#bars become narrower, divided by 10 cubic meters 
ggplot(USGS.flow.data.complete) +
  geom_histogram(aes(x = discharge.mean), binwidth = 10)

#this specifies the number of bins we want the histogram to have and divide accordingly
ggplot(USGS.flow.data.complete) +
  geom_histogram(aes(x = discharge.mean), bins = 20)

#creates bins divided by 10 cubic meters and only goes up to 500 cubic meters. scale_x_continuous limits the scale of the x axis 
ggplot(USGS.flow.data.complete, aes(x = discharge.mean)) +
  geom_histogram(binwidth = 10) + 
  scale_x_continuous(limits = c(0, 500))
  
#uses gage height instead of discharge
ggplot(USGS.flow.data.complete) +
  geom_histogram(aes(x = gage.height.mean))

```
### Frequency line graph (function: geom_freqpoly)

An alternate to a histogram is a frequency polygon graph (distributions of values for continuous numerical variables). Instead of displaying bars,  counts of continuous variables are displayed as lines. This is advantageous if you want to display multiple variables or categories of variables at once.

```{r, fig.height = 3, fig.width = 4}
#three frequency polygons: one for mean, min, and max. if you don't specify color all will be black
ggplot(USGS.flow.data.complete) +
  geom_freqpoly(aes(x = gage.height.mean), bins = 50) +
  geom_freqpoly(aes(x = gage.height.min), bins = 50, color = "blue") +
  geom_freqpoly(aes(x = gage.height.max), bins = 50, color = "red") +
  scale_x_continuous(limits = c(0, 10))

#more measurements approved than pending, color is in aes and based on status of other variable
ggplot(USGS.flow.data.complete) +
  geom_freqpoly(aes(x = gage.height.mean, color = gage.height.mean.approval), bins = 50) +
  scale_x_continuous(limits = c(0, 10)) +
  theme(legend.position = "top")

```
### Box-and-whisker plots (function: geom_boxplot)

A box-and-whisker plot is yet another alternative to histograms (distributions of values for continuous numerical variables). These plots consist of: 

* A box from the 25th to the 75th percentile of the data, called the interquartile range (IQR).

* A bold line inside the box representing the median value of the data. Whether the median is in the center or off to one side of the IQR will give you an idea about the skewness of your data.

* A line outside of the box representing values falling within 1.5 times the IQR. 

* Points representing outliers, values that fall outside 1.5 times the IQR. 

An alternate option is a violin plot, which displays density distributions, somewhat like a hybrid of the box-and-whiskers and the frequency polygon plot.

```{r, fig.height = 3, fig.width = 4}
#splitting up height means based on approval and giving quantiles for each
ggplot(USGS.flow.data.complete) +
  geom_boxplot(aes(x = gage.height.mean.approval, y = gage.height.mean))

#splitting up discharge means by gage height means by 1 unit for each height. take gage height mean, divide it by units of one, and make box plots of discharge based on those heights
ggplot(USGS.flow.data.complete) +
  geom_boxplot(aes(x = gage.height.mean, y = discharge.mean, group = cut_width(gage.height.mean, 1)))

#the greater the amount of samples, the wider the violin, drawing lines at the quantiles 
ggplot(USGS.flow.data.complete) +
  geom_violin(aes(x = gage.height.mean.approval, y = gage.height.mean), draw_quantiles = c(0.25, 0.5, 0.75))
```

Question: what are the pros and cons of each type of frequency graph (histogram, frequency polygon, box-and whisker, violin)?

> Answer: Histograms are good for data distributed more evenly and good for seeing trends and distribution, frequency polygons are good for comparing descriptive statistics of same data, box and whisker are good for identifying trends of data and distribution. Violin looks cool.


### Scatterplot (function: geom_point)
Visualize relationships between continuous numerical variables.

```{r, fig.height = 3, fig.width = 4}
ggplot(USGS.flow.data.complete) +
  geom_point(aes(x = discharge.mean, y = gage.height.mean))

```

## ENDING DISCUSSION

How can multiple options for data exploration inform our understanding of our data? What did you learn about the USGS discharge dataset today?

> ANSWER: 

This passage from R for Data Science sums up some of the questions we should ask ourselves when initially exploring a dataset. "Patterns in your data provide clues about relationships. If a systematic relationship exists between two variables it will appear as a pattern in the data. If you spot a pattern, ask yourself:

"Could this pattern be due to coincidence (i.e. random chance)?

"How can you describe the relationship implied by the pattern?

"How strong is the relationship implied by the pattern?

"What other variables might affect the relationship?

"Does the relationship change if you look at individual subgroups of the data?"

Do you see any patterns in the USGS data for the Eno River? What might be responsible for those patterns and/or relationships?

> ANSWER: 


```{r}

```
